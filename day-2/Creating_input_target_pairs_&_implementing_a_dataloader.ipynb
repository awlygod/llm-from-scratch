{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First will tokenize the whole the VErdict short story we worked with earlier using the BPE tokenizer."
      ],
      "metadata": {
        "id": "D8tEtPmjmh3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqltgTFnnfuA",
        "outputId": "21a7166c-3160-4b8d-afc1-be108c6efe24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "JJo5V004ofhW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pZBuubI-ly97"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF9Lqb6popvn",
        "outputId": "080bc4c3-2c25-40bb-9f42-45ae2e639a6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will remove the first 50 tokens from the datset for demostration purposes"
      ],
      "metadata": {
        "id": "9mz8qb2oqPTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "enc_sample = enc_text[50:]"
      ],
      "metadata": {
        "id": "ieqR8tYApA4s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would now create the input-target pairs for the the nextword prediction taks is to create two variables x and y , where s contains the input tokens and y contains the targets , whch are the inputs shifted by 1:"
      ],
      "metadata": {
        "id": "gD677fTQqbEi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The context size determines how many tokens are included in the input"
      ],
      "metadata": {
        "id": "Xw1IsdtQqzBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_size = 4\n",
        "x = enc_sample[:context_size]\n",
        "y = enc_sample[1:context_size+1]\n",
        "\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y:     {y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUCK409wqYDE",
        "outputId": "35ce6342-f10c-4c72-e459-5e6062917df6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: [290, 4920, 2241, 287]\n",
            "y:     [4920, 2241, 287, 257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(context, \"----->\", desired)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7NMAzVWrN33",
        "outputId": "7b858b1d-28c7-4106-e3be-301b290a86bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290] -----> 4920\n",
            "[290, 4920] -----> 2241\n",
            "[290, 4920, 2241] -----> 287\n",
            "[290, 4920, 2241, 287] -----> 257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here above on left we have input text to the LLM and on right we have the target token ID that the LLM is supposed to predict"
      ],
      "metadata": {
        "id": "tnsQf62Irmm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, context_size+1):\n",
        "  context = enc_sample[:i]\n",
        "  desired = enc_sample[i]\n",
        "  print(tokenizer.decode(context), \"----->\",tokenizer.decode([desired]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDp7MIc5rjb4",
        "outputId": "eeb85e1f-7a09-4df5-a92d-67f3ffc318f9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " and ----->  established\n",
            " and established ----->  himself\n",
            " and established himself ----->  in\n",
            " and established himself in ----->  a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's only one more task before we can turn the tokens into embeddings:implementing an efficient data loader that\n",
        "iterates over the input dataset and returns the inputs and targets as PyTorch tensors, which\n",
        "can be thought of as multidimensional arrays."
      ],
      "metadata": {
        "id": "7ryV0ZFYsgvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Implementing a data loader**"
      ],
      "metadata": {
        "id": "u04PVMtusrsf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Tokenize the entire text\n",
        "    \n",
        "Step 2: Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "\n",
        "Step 3: Return the total number of rows in the dataset\n",
        "\n",
        "Step 4: Return a single row from the dataset"
      ],
      "metadata": {
        "id": "eaWMmBZKs5VY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "MJStlIbetClq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "beMops52tXE6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDatasetV1(Dataset):\n",
        "  def __init__(self, txt, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "\n",
        "    token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i:i + max_length]\n",
        "      target_chunk = token_ids[i + 1:i + max_length + 1]\n",
        "\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "gAVdyVBTthM1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "u7CHZNOTuTgb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Initialize the tokenizer\n",
        "\n",
        "Step 2: Create dataset\n",
        "\n",
        "Step 3: drop_last=True drops the last batch if it is shorter than the specified batch_size to prevent loss spikes\n",
        "during training\n",
        "\n",
        "Step 4: The number of CPU processes to use for preprocessing"
      ],
      "metadata": {
        "id": "_u3HivAvuz_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\",\"r\", encoding = \"utf-8\") as f:\n",
        "  raw_text = f.read()"
      ],
      "metadata": {
        "id": "q7cXLZ3Vudlw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Jv8dvSy_vEtg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PyTorch version:\", torch.__version__)\n",
        "dataloader = create_dataloader_v1(\n",
        "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
        ")\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "first_batch = next(data_iter)\n",
        "print(first_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC0FJfmsvK8h",
        "outputId": "7dcc48a6-88fc-4214-9f54-923fc8fffbca"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "second_batch = next(data_iter)\n",
        "print(second_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCsW18QrvNLs",
        "outputId": "55bb5170-2e02-49ea-cf52-76c9c83f050a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
        "\n",
        "data_iter = iter(dataloader)\n",
        "inputs, targets = next(data_iter)\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Y4jsohvUNW",
        "outputId": "d4045fc8-6127-475c-c248-c45d11deb213"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            " tensor([[   40,   367,  2885,  1464],\n",
            "        [ 1807,  3619,   402,   271],\n",
            "        [10899,  2138,   257,  7026],\n",
            "        [15632,   438,  2016,   257],\n",
            "        [  922,  5891,  1576,   438],\n",
            "        [  568,   340,   373,   645],\n",
            "        [ 1049,  5975,   284,   502],\n",
            "        [  284,  3285,   326,    11]])\n",
            "\n",
            "Targets:\n",
            " tensor([[  367,  2885,  1464,  1807],\n",
            "        [ 3619,   402,   271, 10899],\n",
            "        [ 2138,   257,  7026, 15632],\n",
            "        [  438,  2016,   257,   922],\n",
            "        [ 5891,  1576,   438,   568],\n",
            "        [  340,   373,   645,  1049],\n",
            "        [ 5975,   284,   502,   284],\n",
            "        [ 3285,   326,    11,   287]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we increase the stride to 4. This is to utilize the data set fully (we don't skip a\n",
        "single word) but also avoid any overlap between the batches, since more overlap could lead\n",
        "to increased overfitting."
      ],
      "metadata": {
        "id": "kwfpRvG7vqAc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULoqdoFHvgd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}