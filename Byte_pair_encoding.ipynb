{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Byte Pair Encoding is a subword tokenization algorithm"
      ],
      "metadata": {
        "id": "FoZP-8qHTFkS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jygJLLgS8SK",
        "outputId": "d984602a-94a7-40cd-ef6d-95be363996d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "! pip3 install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "MESxaQD6TjLb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"tiktoken version:\" , importlib.metadata.version('tiktoken'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1PymnG-TpD1",
        "outputId": "03bbe9c7-7a03-4362-bda1-73de59a92a2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "1oisVmNSTw9c"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    \"hello myself  suraj tripathi ! <|endoftext|> In the sunlight terraces\"\n",
        "    \"of someunknownPlace. \"\n",
        ")\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0OS8_0T6s8",
        "outputId": "8e2f6beb-9e2b-4ec5-c07e-87854f9b28f7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[31373, 3589, 220, 969, 1228, 5296, 44202, 5145, 220, 50256, 554, 262, 19606, 8812, 2114, 1659, 617, 34680, 27271, 13, 220]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK-Xdn9rUZ0C",
        "outputId": "205f5277-8fa1-4487-cecc-01ebd35936ed"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello myself  suraj tripathi ! <|endoftext|> In the sunlight terracesof someunknownPlace. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm underlying BPE breaks down words that are not in its predefined vocubulary into smaller subword units or even individual characters.\n",
        "This enables it to handle out of vocabulary words."
      ],
      "metadata": {
        "id": "71bYw3fRV1sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "integers = tokenizer.encode(\"Akwirw ier\")\n",
        "print(integers)\n",
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZQTTLUvUmhB",
        "outputId": "4ace44cc-a9f9-4f1c-fbc2-2de1a5e17ed6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33901, 86, 343, 86, 220, 959]\n",
            "Akwirw ier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "85_G1KNSWZHk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}